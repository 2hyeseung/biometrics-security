{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1871080_이혜승_얼굴 2차_코드.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRbRnTB7l1LA"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD4EAIzPnKrg"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed\n",
        "from keras.models import load_model\n",
        "from numpy import load\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSWPO2FMm4Ez"
      },
      "source": [
        "X_train=[]\n",
        "y_train=[]\n",
        "X_val=[]\n",
        "y_val=[]\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/생체인증보안/02_face_training')\n",
        "# for i in os.listdir():\n",
        "#     img = cv2.imread(i)   \n",
        "#     img = cv2.resize(img,(160,160))\n",
        "#     if(i[5:9]=='0003'):\n",
        "#         X_val.append(img)\n",
        "#         y_val.append(i[0:4])\n",
        "#     else:\n",
        "#         X_train.append(img)\n",
        "#         y_train.append(i[0:4])\n",
        "\n",
        "for i in os.listdir():\n",
        "    img = cv2.imread(i)   \n",
        "    img = cv2.resize(img,(160,160))\n",
        "    if(i[5:9]=='0003'):\n",
        "        X_val.append(img)\n",
        "        y_val.append(i[0:4])\n",
        "        X_train.append(img)\n",
        "        y_train.append(i[0:4])\n",
        "    else:\n",
        "        X_train.append(img)\n",
        "        y_train.append(i[0:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsmK3YRsojNc"
      },
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/생체인증보안/02_face_test')\n",
        "for i in os.listdir():\n",
        "      img = cv2.imread(i)   \n",
        "      img = cv2.resize(img,(160,160))\n",
        "      X_test.append(img)\n",
        "      y_test.append(i.rstrip('.bmp'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr8U0tT6mzBT"
      },
      "source": [
        "print (\"Shape of an image in X_train: \", X_train[0].shape)\n",
        "print (\"Shape of an image in X_train: \", X_val[0].shape)\n",
        "print (\"Shape of an image in X_test: \", X_test[0].shape)\n",
        "print(\"Total categories: \", len(np.unique(y_train)))\n",
        "print(\"Total categories: \", len(np.unique(y_val)))\n",
        "print(\"Total categories: \", len(np.unique(y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2d5m_OvnaSC"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=350)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "y_val = le.fit_transform(y_val)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=350)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val=np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0_PQXUqswa0"
      },
      "source": [
        "from numpy import asarray\n",
        "print(\"X_train Shape: \", X_train.shape)\n",
        "print(\"y_train Shape: \", y_train.shape)\n",
        "\n",
        "print(\"X_val Shape: \", X_val.shape)\n",
        "print(\"y_val Shape: \", y_val.shape)\n",
        "\n",
        "print(\"y_test Shape: \", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMno1wgx2AoP"
      },
      "source": [
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# datagen = ImageDataGenerator(\n",
        "#         width_shift_range=0.1,\n",
        "#         height_shift_range=0.1,\n",
        "#         rescale=1./255,\n",
        "#         zoom_range=0.1,\n",
        "#         brightness_range=[0.2,1.0],\n",
        "#         fill_mode='constant')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSLczML2BsHj"
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    # blur images with a sigma of 0 to 0.5\n",
        "    iaa.GaussianBlur(sigma=(0, 0.5)),\n",
        "    iaa.Affine(\n",
        "        # scale images to 90-110% of their size, individually per axis\n",
        "        scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
        "        # translate by -10 to +10 percent (per axis)\n",
        "        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
        "        # if mode is constant, use a cval between 0 and 255\n",
        "        cval=255,\n",
        "    )\n",
        "], random_order=True)\n",
        "\n",
        "x=X_train\n",
        "y=y_train\n",
        "aug=20\n",
        "\n",
        "for i in range(aug):\n",
        "\tx_aug=seq.augment_images(x)\n",
        "\tX_train=np.append(X_train, x_aug, axis=0)\n",
        "\ty_train=np.append(y_train, y, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1RtOAETqRd5"
      },
      "source": [
        "from numpy import asarray\n",
        "print(\"X_train Shape: \", X_train.shape)\n",
        "print(\"y_train Shape: \", y_train.shape)\n",
        "\n",
        "print(\"X_val Shape: \", X_val.shape)\n",
        "print(\"y_val Shape: \", y_val.shape)\n",
        "\n",
        "print(\"y_test Shape: \", X_test.shape)\n",
        "\n",
        "# print(\"X_train_aug Shape: \", X_train_aug.shape)\n",
        "# print(\"y_train_aug Shape: \", y_train_aug.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv1-Ovqs7hGw"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, Dropout, Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "def get_model():\n",
        "    m1=Sequential()\n",
        "    m1.add(BatchNormalization(input_shape = (160,160,3)))\n",
        "    m1.add(Convolution2D(32, (3,3), activation ='relu', input_shape = (160, 160, 3))) \n",
        "    m1.add(MaxPooling2D(pool_size=2))\n",
        "    m1.add(Convolution2D(filters=6,kernel_size=4,padding='same',activation='relu'))\n",
        "    m1.add(MaxPooling2D(pool_size=2))\n",
        "    m1.add(Convolution2D(filters=160,kernel_size=3,padding='same',activation='relu'))\n",
        "    m1.add(MaxPooling2D(pool_size=2))\n",
        "    m1.add(Convolution2D(filters=160,kernel_size=2,padding='same',activation='relu'))\n",
        "    m1.add(MaxPooling2D(pool_size=2))\n",
        "    m1.add(Flatten()) \n",
        "    m1.add(Dense(units=160,activation = 'relu'))\n",
        "    m1.add(Dense(units = 64, activation = 'relu'))\n",
        "    m1.add(Dense(units = 32, activation = 'relu'))\n",
        "    m1.add(Dense(units = 350, activation = 'softmax'))\n",
        "    m1.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
        "    return m1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW5c-2MD7jCi"
      },
      "source": [
        "from sklearn.model_selection import KFold \n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "kfold = KFold(n_splits=5, random_state = 2021, shuffle=True)\n",
        "acc_list = [] \n",
        "# for train_index, val_index in kfold.split(X_train):\n",
        "#     x_train_fold, x_val_fold = X_train[train_index], X_train[val_index]\n",
        "#     y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "#     model = get_model()\n",
        "#     model.fit(x_train_fold, y_train_fold, epochs = 30, validation_data = (x_val_fold, y_val_fold))\n",
        "\n",
        "#     _, acc = model.evaluate(X_val,y_val)\n",
        "#     acc_list.append(round(acc,4))\n",
        "\n",
        "model.fit(X_train, y_train, epochs=30, validation_data=(X_val,y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSrP0XYQZJV6"
      },
      "source": [
        "# print(acc_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLaDFGrVZK_D"
      },
      "source": [
        "predicted = model.predict(X_test, batch_size=350)\n",
        "predicted = np.argmax(np.round(predicted),axis=1)\n",
        "print(\"Prediction :\",predicted)\n",
        "print(y_test)\n",
        "predicted=predicted.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp-NsoYeae7r"
      },
      "source": [
        "for i in range(700):\n",
        "    predicted[i]+=1\n",
        "\n",
        "y_test = map(int, y_test)\n",
        "result = { name:value for name, value in zip(y_test, predicted) }\n",
        "result = sorted(result.items())\n",
        "\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QTh3s_waWIY"
      },
      "source": [
        "import csv\n",
        "with open('187180_이혜승_얼굴_2차_답안.csv', 'w', newline='') as file:\n",
        "    mywriter = csv.writer(file, delimiter=',')\n",
        "    mywriter.writerows(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}