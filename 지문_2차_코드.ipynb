{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "지문인식2차.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjIvDsEvCzdN"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thR9jq5qBxfp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from zipfile import ZipFile\n",
        "import os,glob\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize \n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import warnings\n",
        "from scipy import ndarray\n",
        "import skimage as sk\n",
        "from skimage import transform\n",
        "from skimage import util\n",
        "from skimage import io\n",
        "from sklearn import metrics\n",
        "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, Dropout, Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import LeakyReLU\n",
        "from numpy import asarray\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import pathlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqSLZL43B7Rg"
      },
      "source": [
        "# Train Data\n",
        "\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "\n",
        "filepath='/content/drive/MyDrive/생체인증보안/01_finger_test'\n",
        "filepath = pathlib.Path(filepath)\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/생체인증보안/01_finger_training/1')\n",
        "for i in os.listdir():\n",
        "      img = cv2.imread(i)   \n",
        "      img = cv2.resize(img,(128,128))\n",
        "      X_train.append(img)\n",
        "      y_train.append('1')\n",
        "os.chdir('/content/drive/MyDrive/생체인증보안/01_finger_training/2')\n",
        "for i in os.listdir():\n",
        "      img = cv2.imread(i)   \n",
        "      img = cv2.resize(img,(128,128))\n",
        "      X_train.append(img)\n",
        "      y_train.append('2')\n",
        "os.chdir('/content/drive/MyDrive/생체인증보안/01_finger_training/3')\n",
        "for i in os.listdir():\n",
        "      img = cv2.imread(i)   \n",
        "      img = cv2.resize(img,(128,128))\n",
        "      X_train.append(img)\n",
        "      y_train.append('3')\n",
        "os.chdir('/content/drive/MyDrive/생체인증보안/01_finger_training/4')\n",
        "for i in os.listdir():\n",
        "      img = cv2.imread(i)   \n",
        "      img = cv2.resize(img,(128,128))\n",
        "      X_train.append(img)\n",
        "      y_train.append('4')\n",
        "os.chdir('/content/drive/MyDrive/생체인증보안/01_finger_training/5')\n",
        "for i in os.listdir():\n",
        "      img = cv2.imread(i)   \n",
        "      img = cv2.resize(img,(128,128))\n",
        "      X_train.append(img)\n",
        "      y_train.append('5')\n",
        "os.chdir('/content/drive/MyDrive/생체인증보안/01_finger_training/6')\n",
        "for i in os.listdir():\n",
        "      img = cv2.imread(i)   \n",
        "      img = cv2.resize(img,(128,128))\n",
        "      X_train.append(img)\n",
        "      y_train.append('6')\n",
        "os.chdir('/content/drive/MyDrive/생체인증보안/01_finger_training/7')\n",
        "for i in os.listdir():\n",
        "      img = cv2.imread(i)   \n",
        "      img = cv2.resize(img,(128,128))\n",
        "      X_train.append(img)\n",
        "      y_train.append('7')\n",
        "os.chdir('/content/drive/MyDrive/생체인증보안/01_finger_training/8')\n",
        "for i in os.listdir():\n",
        "      img = cv2.imread(i)   \n",
        "      img = cv2.resize(img,(128,128))\n",
        "      X_train.append(img)\n",
        "      y_train.append('8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWeE5oxnEBsT"
      },
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "filepath='/content/drive/MyDrive/생체인증보안/01_finger_test'\n",
        "filepath = pathlib.Path(filepath)\n",
        "\n",
        "# for item in filepath.glob(\"*\"):\n",
        "#     print(item.name.rstrip('.bmp'))\n",
        "#     testset_name.append(item.name.rstrip('.bmp'))\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/생체인증보안/01_finger_test')\n",
        "for i in tqdm(os.listdir()):\n",
        "      img = cv2.imread(i)   \n",
        "      img = cv2.resize(img,(128,128))\n",
        "      X_test.append(img)\n",
        "      y_test.append(i.rstrip('.bmp'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0L_mTnAG3zg"
      },
      "source": [
        "print (\"Shape of an image in X_train: \", X_train[0].shape)\n",
        "print (\"Shape of an image in X_test: \", X_test[0].shape)\n",
        "print(\"Total categories: \", len(np.unique(y_train)))\n",
        "print(\"Total categories: \", len(np.unique(y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhZfyzZkHFiP"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=8)\n",
        "y_train = np.array(y_train)\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4T-OjA5LlUl"
      },
      "source": [
        "# import numpy as np\n",
        "# y_train = np.array(y_train)\n",
        "# print(y_train.shape)\n",
        "# # y_train = le.fit_transform(y_train)\n",
        "# # y_train = tf.keras.utils.to_categorical(y_train, num_classes=8)\n",
        "# # print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MT6HB2MIuCj"
      },
      "source": [
        "print(\"X_train Shape: \", X_train.shape)\n",
        "print(\"y_train Shape: \", y_train.shape)\n",
        "print(\"y_test Shape: \", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zk-LOIUJDpt"
      },
      "source": [
        "def get_model():\n",
        "    m1=Sequential()\n",
        "    m1.add(BatchNormalization(input_shape = (128,128,3)))\n",
        "    m1.add(Convolution2D(32, (3,3), activation ='relu', input_shape = (128, 128, 3))) \n",
        "    m1.add(MaxPooling2D(pool_size=2))\n",
        "    m1.add(Convolution2D(filters=6,kernel_size=4,padding='same',activation='relu'))\n",
        "    m1.add(MaxPooling2D(pool_size=2))\n",
        "    m1.add(Convolution2D(filters=128,kernel_size=3,padding='same',activation='relu'))\n",
        "    m1.add(MaxPooling2D(pool_size=2))\n",
        "    m1.add(Convolution2D(filters=128,kernel_size=2,padding='same',activation='relu'))\n",
        "    m1.add(MaxPooling2D(pool_size=2))\n",
        "    m1.add(Flatten()) \n",
        "    m1.add(Dense(units=128,activation = 'relu'))\n",
        "    m1.add(Dense(units = 64, activation = 'relu'))\n",
        "    m1.add(Dense(units = 32, activation = 'relu'))\n",
        "    m1.add(Dense(units = 8, activation = 'softmax'))\n",
        "    m1.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
        "    return m1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDHuBZaOJUnQ"
      },
      "source": [
        "from sklearn.model_selection import KFold \n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "kfold = KFold(n_splits=4, random_state = 2021, shuffle=True)\n",
        "acc_list = [] \n",
        "for train_index, val_index in kfold.split(X_train):\n",
        "    x_train_fold, x_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "    model = get_model()\n",
        "    model.fit(x_train_fold, y_train_fold, epochs = 50, validation_data = (x_val_fold, y_val_fold))\n",
        "\n",
        "    _, acc = model.evaluate(X_train, y_train)\n",
        "    acc_list.append(round(acc,4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YXDMXbhPzI8"
      },
      "source": [
        "print(acc_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdchk07qP2F3"
      },
      "source": [
        "predicted = model.predict(X_test, batch_size=80)\n",
        "predicted = np.argmax(np.round(predicted),axis=1)\n",
        "print(\"Prediction :\",predicted)\n",
        "print(y_test)\n",
        "predicted=predicted.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFM1DvA6rRWy"
      },
      "source": [
        "for i in range(80):\n",
        "    predicted[i]+=1\n",
        "\n",
        "y_test = map(int, y_test)\n",
        "result = { name:value for name, value in zip(y_test, predicted) }\n",
        "result = sorted(result.items())\n",
        "\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrO912hFxSqO"
      },
      "source": [
        "import csv\n",
        "with open('187180_이혜승_지문_2차_답안.csv', 'w', newline='') as file:\n",
        "    mywriter = csv.writer(file, delimiter=',')\n",
        "    mywriter.writerows(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}